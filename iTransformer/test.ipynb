{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from experiments.exp_long_term_forecasting_partial import Exp_Long_Term_Forecast_Partial\n",
    "from experiments.exp_long_term_forecasting import Exp_Long_Term_Forecast\n",
    "from data_provider.data_factory import data_provider\n",
    "from model.iTransformer import Model\n",
    "import random\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from utils.load import parse_bash_script, default_config, merge_args\n",
    "\n",
    "fix_seed = 2024\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Model.__init__() missing 1 required positional argument: 'configs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoints/custom-model_iTransformer_custom_S_ft96_sl48_ll96_pl128_dm8_nh2_el1_dl128_df1_fctimeF_ebTrue_dtExp_projection_0/checkpoint.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: Model.__init__() missing 1 required positional argument: 'configs'"
     ]
    }
   ],
   "source": [
    "bash_script_file = 'scripts/best_MS.sh'  # Replace with your bash script file name\n",
    "with open(bash_script_file, 'r') as f:\n",
    "    script_content = f.read()\n",
    "\n",
    "bash_args = parse_bash_script(script_content)\n",
    "bash_args.model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = default_config().parse_args()\n",
    "default_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = merge_args(bash_args, default_args)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "            args.model_id,\n",
    "            args.model,\n",
    "            args.data,\n",
    "            args.features,\n",
    "            args.seq_len,\n",
    "            args.label_len,\n",
    "            args.pred_len,\n",
    "            args.d_model,\n",
    "            args.n_heads,\n",
    "            args.e_layers,\n",
    "            args.d_layers,\n",
    "            args.d_ff,\n",
    "            args.factor,\n",
    "            args.embed,\n",
    "            args.distil,\n",
    "            args.des,\n",
    "            args.class_strategy, 0)\n",
    "setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Exp_Long_Term_Forecast(args)\n",
    "exp.model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.test(setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.is_training = 0 \n",
    "exp = Exp_Long_Term_Forecast_Partial(args)\n",
    "exp.model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))\n",
    "exp.predict(setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, mse, rmse, mape, mspe = np.load(os.path.join('results/' + setting, 'metrics.npy'))\n",
    "preds = np.load(os.path.join('results/' + setting, 'pred.npy'))\n",
    "trues = np.load(os.path.join('results/' + setting, 'true.npy'))\n",
    "real_pred = np.load(os.path.join('results/' + setting, 'real_prediction.npy'))\n",
    "train_loss = np.load(os.path.join('results/' + setting, 'train_loss.npy'))\n",
    "val_loss = np.load(os.path.join('results/' + setting, 'val_loss.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.5891405 ],\n",
       "        [0.5891405 ],\n",
       "        [0.5891405 ],\n",
       "        ...,\n",
       "        [0.47864905],\n",
       "        [0.47864905],\n",
       "        [0.5368024 ]],\n",
       "\n",
       "       [[0.5891405 ],\n",
       "        [0.5891405 ],\n",
       "        [0.5891405 ],\n",
       "        ...,\n",
       "        [0.47864905],\n",
       "        [0.5368024 ],\n",
       "        [0.5019104 ]],\n",
       "\n",
       "       [[0.5891405 ],\n",
       "        [0.5891405 ],\n",
       "        [0.5891405 ],\n",
       "        ...,\n",
       "        [0.5368024 ],\n",
       "        [0.5019104 ],\n",
       "        [0.4902797 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[2.5430944 ],\n",
       "        [2.54891   ],\n",
       "        [2.54891   ],\n",
       "        ...,\n",
       "        [2.4791257 ],\n",
       "        [2.3860803 ],\n",
       "        [2.4093418 ]],\n",
       "\n",
       "       [[2.54891   ],\n",
       "        [2.54891   ],\n",
       "        [2.5721712 ],\n",
       "        ...,\n",
       "        [2.3860803 ],\n",
       "        [2.4093418 ],\n",
       "        [2.4093418 ]],\n",
       "\n",
       "       [[2.54891   ],\n",
       "        [2.5721712 ],\n",
       "        [2.4558644 ],\n",
       "        ...,\n",
       "        [2.4093418 ],\n",
       "        [2.4093418 ],\n",
       "        [2.4093418 ]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68322264, 0.60529286, 0.57409283, 0.56181302, 0.55694538])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(train_loss)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_loss)\n",
    "plt.title('Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('D:/FPT/SU24/DSP391m/code/crawl/data/clean/df_combine.csv')\n",
    "test_df = df.iloc[3914:]\n",
    "y_test = test_df.Sell.to_list()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the 3D array to 1D and convert to list\n",
    "pred_flattened = real_pred.flatten().tolist()\n",
    "len(pred_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure y_test and pred_flattened are the same length\n",
    "assert len(y_test) == len(pred_flattened), \"Lengths of y_test and pred do not match!\"\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test, label='True Values', marker='o')\n",
    "plt.plot(pred_flattened, label='Predicted Values', marker='x')\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
